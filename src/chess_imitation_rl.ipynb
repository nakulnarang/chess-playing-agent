{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Bcx9darS1Th",
        "outputId": "88b9aead-1a91-4f3b-e9c0-ac5964f1cd81"
      },
      "outputs": [],
      "source": [
        "!pip install requests python-chess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jb9Yaorn5tjw",
        "outputId": "1b6a0fe8-1aca-442b-edf4-a63969a1ad04"
      },
      "outputs": [],
      "source": [
        "!pip install gymnasium stable-baselines3[extra]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhkMyhOH2Vqh"
      },
      "source": [
        "# **Import Statements**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "83qB9Rhz1k_-"
      },
      "outputs": [],
      "source": [
        "import chess\n",
        "import chess.pgn\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from collections import deque\n",
        "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
        "import requests\n",
        "import bz2\n",
        "import os \n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.policies import ActorCriticPolicy\n",
        "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "from torch.distributions import Categorical \n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZPx3s0U2eZN"
      },
      "source": [
        "# **Constants**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6V9ikq-i1pET"
      },
      "outputs": [],
      "source": [
        "QUEEN_DIR_OFFSETS = [\n",
        "    (0, 1), (1, 1), (1, 0), (1, -1),\n",
        "    (0, -1), (-1, -1), (-1, 0), (-1, 1)\n",
        "] \n",
        "QUEEN_LIKE_MOVES_PLANES = 56\n",
        "\n",
        "KNIGHT_MOVES_OFFSETS = [\n",
        "    (1, 2), (2, 1), (2, -1), (1, -2),\n",
        "    (-1, -2), (-2, -1), (-2, 1), (-1, 2)\n",
        "]\n",
        "KNIGHT_MOVES_PLANES = 8\n",
        "\n",
        "PAWN_PROMOTION_TYPES = [\n",
        "    (0, 1),   \n",
        "    (-1, 1),  \n",
        "    (1, 1)    \n",
        "]\n",
        "PROMOTION_PIECES_ORDER = [chess.QUEEN, chess.ROOK, chess.BISHOP]\n",
        "PAWN_PROMOTION_PLANES = 9 \n",
        "\n",
        "TOTAL_ACTION_PLANES = QUEEN_LIKE_MOVES_PLANES + KNIGHT_MOVES_PLANES + PAWN_PROMOTION_PLANES \n",
        "POLICY_OUTPUT_SIZE = TOTAL_ACTION_PLANES * 64 \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClRMTIGm2mvE"
      },
      "source": [
        "# **Data Extraction**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BhujZHqB1uGQ"
      },
      "outputs": [],
      "source": [
        "def download_magnus_carlsen_game(username: str, max_games: int = 1, perf_type: str = None, output_filename: str = \"games.pgn\"):\n",
        "    print(f\"Attempting to download {max_games} {perf_type if perf_type else 'any'} game(s) for user: {username}\")\n",
        "    url = f\"https://lichess.org/api/games/user/{username}\"\n",
        "    params = {\n",
        "        'max': max_games,\n",
        "        'perfType': perf_type,\n",
        "        'moves': 1, \n",
        "        'pgnInJson': 0,\n",
        "        'clocks': 0, \n",
        "        'evals': 0, \n",
        "        'opening': 0,\n",
        "        'sort': 'dateDesc'\n",
        "    }\n",
        "\n",
        "    headers = {\n",
        "        'Accept': 'application/x-chess-pgn',\n",
        "        'User-Agent': 'YourChessEngineProject/1.0 (contact@example.com)' \n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url, params=params, headers=headers, stream=True)\n",
        "        response.raise_for_status() \n",
        "\n",
        "        content_encoding = response.headers.get('Content-Encoding', '')\n",
        "\n",
        "        output_filepath = output_filename\n",
        "\n",
        "        with open(output_filepath, 'wb') as f:\n",
        "            if 'bz2' in content_encoding:\n",
        "                print(\"  Content-Encoding: bz2 detected. Decompressing...\")\n",
        "                decompressor = bz2.BZ2Decompressor()\n",
        "                for chunk in response.iter_content(chunk_size=8192):\n",
        "                    if chunk:\n",
        "                        try:\n",
        "                            f.write(decompressor.decompress(chunk))\n",
        "                        except bz2.BZ2Error as e:\n",
        "                            print(f\"Error decompressing BZ2 data: {e}. The downloaded file might be corrupted or not valid BZ2.\")\n",
        "                            os.remove(output_filepath)\n",
        "                            raise \n",
        "            else:\n",
        "                print(\"  No bz2 Content-Encoding detected. Writing directly...\")\n",
        "                for chunk in response.iter_content(chunk_size=8192):\n",
        "                    if chunk:\n",
        "                        f.write(chunk)\n",
        "\n",
        "        if os.path.exists(output_filepath) and os.path.getsize(output_filepath) > 0:\n",
        "            print(f\"Successfully downloaded PGN to: {output_filepath}\")\n",
        "\n",
        "            try:\n",
        "                with open(output_filepath, 'r', encoding='utf-8') as pgn_file:\n",
        "                    game = chess.pgn.read_game(pgn_file)\n",
        "                    if game:\n",
        "                        print(\"\\n--- Game Information ---\")\n",
        "                        print(f\"Event: {game.headers.get('Event')}\")\n",
        "                        print(f\"Site: {game.headers.get('Site')}\")\n",
        "                        print(f\"Date: {game.headers.get('Date')}\")\n",
        "                        print(f\"White: {game.headers.get('White')} (Elo: {game.headers.get('WhiteElo')})\")\n",
        "                        print(f\"Black: {game.headers.get('Black')} (Elo: {game.headers.get('BlackElo')})\")\n",
        "                        print(f\"Result: {game.headers.get('Result')}\")\n",
        "                        print(f\"ECO (Opening): {game.headers.get('ECO')}\")\n",
        "                        print(f\"TimeControl: {game.headers.get('TimeControl')}\")\n",
        "                        print(f\"Termination: {game.headers.get('Termination')}\")\n",
        "                        print(\"-\" * 20)\n",
        "                    else:\n",
        "                        print(f\"No game data found in the downloaded PGN: {output_filepath}. File might be empty or malformed.\")\n",
        "                        os.remove(output_filepath)\n",
        "            except Exception as e:\n",
        "                print(f\"Error reading downloaded PGN file: {e}. File might be corrupted.\")\n",
        "                os.remove(output_filepath)\n",
        "        else:\n",
        "            print(f\"Downloaded PGN file is empty or missing: {output_filepath}.\")\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error downloading PGN: {e}\")\n",
        "    except bz2.BZ2Error as e: \n",
        "        print(f\"Caught a BZ2 decompression error: {e}. This likely means the data wasn't valid BZ2, or the file was corrupted during download.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1isnR0M2zOs"
      },
      "source": [
        "# **Encoding Board State and Action Move and Decoding Move**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1FyhJsMX2Cpe"
      },
      "outputs": [],
      "source": [
        "def encode_board_lc0(board: chess.Board, history: deque) -> np.ndarray:\n",
        "    \n",
        "    NUM_HISTORY_FRAMES = 8\n",
        "    PLANES_PER_FRAME = 14\n",
        "    AUX_PLANES = 7\n",
        "    NUM_PLANES = (NUM_HISTORY_FRAMES * PLANES_PER_FRAME) + AUX_PLANES\n",
        "\n",
        "    encoded_state = np.zeros((NUM_PLANES, 8, 8), dtype=np.float32)\n",
        "\n",
        "    piece_plane_map = {\n",
        "        chess.PAWN: 0, chess.KNIGHT: 1, chess.BISHOP: 2,\n",
        "        chess.ROOK: 3, chess.QUEEN: 4, chess.KING: 5\n",
        "    }\n",
        "\n",
        "    all_boards = list(history) + [board]\n",
        "    all_boards = all_boards[-NUM_HISTORY_FRAMES:]\n",
        "\n",
        "    for i, historical_board in enumerate(reversed(all_boards)):\n",
        "        frame_offset = i * PLANES_PER_FRAME\n",
        "\n",
        "        for sq in chess.SQUARES:\n",
        "            piece = historical_board.piece_at(sq)\n",
        "            if piece:\n",
        "                plane_idx = piece_plane_map[piece.piece_type]\n",
        "                if piece.color != historical_board.turn: \n",
        "                    plane_idx += 6 \n",
        "\n",
        "                rank = chess.square_rank(sq)\n",
        "                file = chess.square_file(sq)\n",
        "                encoded_state[frame_offset + plane_idx, rank, file] = 1\n",
        "\n",
        "        encoded_state[frame_offset + 12, :, :] = 1 if historical_board.turn == historical_board.turn else 0 \n",
        "\n",
        "        if historical_board.ep_square is not None:\n",
        "            rank = chess.square_rank(historical_board.ep_square)\n",
        "            file = chess.square_file(historical_board.ep_square)\n",
        "            encoded_state[frame_offset + 13, rank, file] = 1\n",
        "\n",
        "    aux_offset = NUM_HISTORY_FRAMES * PLANES_PER_FRAME\n",
        "\n",
        "    if board.has_kingside_castling_rights(chess.WHITE):\n",
        "        encoded_state[aux_offset + 0, :, :] = 1\n",
        "    if board.has_queenside_castling_rights(chess.WHITE):\n",
        "        encoded_state[aux_offset + 1, :, :] = 1\n",
        "    if board.has_kingside_castling_rights(chess.BLACK):\n",
        "        encoded_state[aux_offset + 2, :, :] = 1\n",
        "    if board.has_queenside_castling_rights(chess.BLACK):\n",
        "        encoded_state[aux_offset + 3, :, :] = 1\n",
        "\n",
        "    encoded_state[aux_offset + 4, :, :] = board.halfmove_clock / 100.0\n",
        "\n",
        "    encoded_state[aux_offset + 5, :, :] = board.fullmove_number / 200.0\n",
        "\n",
        "    if board.is_repetition():\n",
        "        encoded_state[aux_offset + 6, :, :] = 1\n",
        "\n",
        "    if board.turn == chess.BLACK:\n",
        "        encoded_state = np.rot90(encoded_state, k=2, axes=(1, 2))\n",
        "\n",
        "        for i in range(NUM_HISTORY_FRAMES):\n",
        "            frame_offset = i * PLANES_PER_FRAME\n",
        "            for j in range(6): \n",
        "                temp = np.copy(encoded_state[frame_offset + j, :, :])\n",
        "                encoded_state[frame_offset + j, :, :] = encoded_state[frame_offset + j + 6, :, :]\n",
        "                encoded_state[frame_offset + j + 6, :, :] = temp\n",
        "\n",
        "        temp = np.copy(encoded_state[aux_offset + 0, :, :]) \n",
        "        encoded_state[aux_offset + 0, :, :] = encoded_state[aux_offset + 2, :, :] \n",
        "        encoded_state[aux_offset + 2, :, :] = temp\n",
        "\n",
        "        temp = np.copy(encoded_state[aux_offset + 1, :, :]) \n",
        "        encoded_state[aux_offset + 1, :, :] = encoded_state[aux_offset + 3, :, :] \n",
        "        encoded_state[aux_offset + 3, :, :] = temp\n",
        "\n",
        "    return encoded_state\n",
        "\n",
        "def get_action_plane_idx_lc0(move: chess.Move, board: chess.Board) -> int:\n",
        "    \n",
        "    from_sq = move.from_square\n",
        "    to_sq = move.to_square\n",
        "\n",
        "    if board.turn == chess.BLACK:\n",
        "        from_sq = chess.square_mirror(from_sq)\n",
        "        to_sq = chess.square_mirror(to_sq)\n",
        "\n",
        "    from_rank, from_file = chess.square_rank(from_sq), chess.square_file(from_sq)\n",
        "    to_rank, to_file = chess.square_rank(to_sq), chess.square_file(to_sq)\n",
        "\n",
        "    dx = to_file - from_file\n",
        "    dy = to_rank - from_rank\n",
        "\n",
        "    if move.promotion:\n",
        "        try:\n",
        "            promotion_piece_idx = PROMOTION_PIECES_ORDER.index(move.promotion)\n",
        "        except ValueError:\n",
        "            if move.promotion == chess.KNIGHT:\n",
        "                promotion_piece_idx = PROMOTION_PIECES_ORDER.index(chess.QUEEN)\n",
        "            else:\n",
        "                raise ValueError(f\"Unexpected promotion piece: {move.promotion} in move {move.uci()}\")\n",
        "\n",
        "        if dx == 0:\n",
        "            pawn_move_type_idx = 0\n",
        "        elif dx == -1: \n",
        "            pawn_move_type_idx = 1\n",
        "        elif dx == 1: \n",
        "            pawn_move_type_idx = 2\n",
        "        else:\n",
        "            raise ValueError(f\"Invalid pawn promotion dx: {dx} for move {move.uci()}\")\n",
        "\n",
        "        action_plane_idx = QUEEN_LIKE_MOVES_PLANES + KNIGHT_MOVES_PLANES + \\\n",
        "                           (promotion_piece_idx * 3) + pawn_move_type_idx\n",
        "        return action_plane_idx\n",
        "\n",
        "    knight_move_delta = (dx, dy)\n",
        "    if knight_move_delta in KNIGHT_MOVES_OFFSETS:\n",
        "        action_plane_idx = QUEEN_LIKE_MOVES_PLANES + KNIGHT_MOVES_OFFSETS.index(knight_move_delta)\n",
        "        return action_plane_idx\n",
        "\n",
        "\n",
        "    abs_dx = abs(dx)\n",
        "    abs_dy = abs(dy)\n",
        "\n",
        "\n",
        "    if (abs_dx == 0 and abs_dy > 0) or \\\n",
        "       (abs_dy == 0 and abs_dx > 0) or \\\n",
        "       (abs_dx == abs_dy and abs_dx > 0):\n",
        "\n",
        "        distance = max(abs_dx, abs_dy)\n",
        "        if distance == 0 or distance > 7:\n",
        "            raise ValueError(f\"Invalid distance {distance} for ray move: {move.uci()}\")\n",
        "\n",
        "        norm_dx = dx // distance if distance > 0 else 0\n",
        "        norm_dy = dy // distance if distance > 0 else 0\n",
        "\n",
        "        try:\n",
        "            direction_idx = QUEEN_DIR_OFFSETS.index((norm_dx, norm_dy))\n",
        "        except ValueError:\n",
        "            raise ValueError(f\"Invalid direction for ray move: {move.uci()} (dx={dx}, dy={dy})\")\n",
        "\n",
        "        action_plane_idx = direction_idx * 7 + (distance - 1)\n",
        "        return action_plane_idx\n",
        "\n",
        "    raise ValueError(f\"Move {move.uci()} from {board.fen()} does not fit Lc0 action plane scheme.\")\n",
        "\n",
        "def encode_move_lc0_style(move: chess.Move, board: chess.Board) -> int:\n",
        "    \n",
        "    from_sq_encoded = move.from_square\n",
        "    if board.turn == chess.BLACK:\n",
        "        from_sq_encoded = chess.square_mirror(from_sq_encoded)\n",
        "\n",
        "    action_plane_idx = get_action_plane_idx_lc0(move, board)\n",
        "\n",
        "    return from_sq_encoded * TOTAL_ACTION_PLANES + action_plane_idx\n",
        "\n",
        "def decode_move_lc0_style(predicted_idx: int, board: chess.Board) -> chess.Move:\n",
        "    \n",
        "    from_sq_pred = predicted_idx // TOTAL_ACTION_PLANES\n",
        "    action_plane_idx_pred = predicted_idx % TOTAL_ACTION_PLANES\n",
        "\n",
        "    if board.turn == chess.BLACK:\n",
        "        from_sq_pred = chess.square_mirror(from_sq_pred)\n",
        "\n",
        "    for legal_move in board.legal_moves:\n",
        "        try:\n",
        "            encoded_legal_move_idx = encode_move_lc0_style(legal_move, board)\n",
        "            if encoded_legal_move_idx == predicted_idx:\n",
        "                return legal_move\n",
        "        except ValueError:\n",
        "            pass\n",
        "\n",
        "    print(f\"Warning: No direct legal move found for predicted index {predicted_idx} on board {board.fen()}. Returning random legal move.\")\n",
        "    if board.legal_moves:\n",
        "        return next(iter(board.legal_moves))\n",
        "    else:\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dhn7cbR3B7O"
      },
      "source": [
        "# **Dataset Creation and Processing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nc5ma6Cs2J1m"
      },
      "outputs": [],
      "source": [
        "def process_pgn_to_training_data_lc0(pgn_filepath: str, num_history_frames: int = 7):\n",
        "    \n",
        "    X_boards = [] \n",
        "    Y_policy_moves = []\n",
        "    Y_value_results = []\n",
        "\n",
        "    print(f\"Processing PGN file: {pgn_filepath}\")\n",
        "\n",
        "    try:\n",
        "        with open(pgn_filepath, encoding=\"utf-8\") as pgn_file:\n",
        "            game_counter = 0\n",
        "            while True:\n",
        "                game = chess.pgn.read_game(pgn_file)\n",
        "                if game is None:\n",
        "                    break\n",
        "\n",
        "                game_counter += 1\n",
        "                if game_counter % 100 == 0:\n",
        "                    print(f\"  Processed {game_counter} games...\")\n",
        "\n",
        "                board = game.board()\n",
        "                history_boards = deque([board.copy() for _ in range(num_history_frames)], maxlen=num_history_frames)\n",
        "\n",
        "                result_str = game.headers.get(\"Result\")\n",
        "                game_result = 0.0 \n",
        "\n",
        "                if result_str == \"1-0\":\n",
        "                    game_result = 1.0 \n",
        "                elif result_str == \"0-1\":\n",
        "                    game_result = -1.0 \n",
        "\n",
        "                for move in game.mainline_moves():\n",
        "                    encoded_board_state = encode_board_lc0(board, history_boards)\n",
        "                    X_boards.append(encoded_board_state)\n",
        "\n",
        "                    encoded_expert_move = encode_move_lc0_style(move, board)\n",
        "                    Y_policy_moves.append(encoded_expert_move)\n",
        "\n",
        "                    value_for_current_player = game_result\n",
        "                    if board.turn == chess.BLACK:\n",
        "                        value_for_current_player *= -1.0 \n",
        "\n",
        "                    Y_value_results.append(value_for_current_player)\n",
        "\n",
        "                    history_boards.append(board.copy()) \n",
        "                    board.push(move)\n",
        "\n",
        "        print(f\"Finished processing {game_counter} games.\")\n",
        "\n",
        "        X_train = np.array(X_boards, dtype=np.float32)\n",
        "        Y_policy_train = np.array(Y_policy_moves, dtype=np.int64) \n",
        "        Y_value_train = np.array(Y_value_results, dtype=np.float32) \n",
        "\n",
        "        print(f\"X_train shape: {X_train.shape}\")\n",
        "        print(f\"Y_policy_train shape: {Y_policy_train.shape}\")\n",
        "        print(f\"Y_value_train shape: {Y_value_train.shape}\")\n",
        "\n",
        "\n",
        "        return X_train, Y_policy_train, Y_value_train\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: PGN file not found at {pgn_filepath}\")\n",
        "        return None, None, None\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while processing PGN: {e}\")\n",
        "        return None, None, None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4_X7JBR3KAM"
      },
      "source": [
        "# **Network Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_HLDNQxQ2RRr"
      },
      "outputs": [],
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, num_channels):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(num_channels, num_channels, kernel_size=3, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(num_channels)\n",
        "        self.conv2 = nn.Conv2d(num_channels, num_channels, kernel_size=3, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(num_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += identity \n",
        "        return F.relu(out)\n",
        "\n",
        "class ChessNet(nn.Module):\n",
        "    def __init__(self, num_residual_blocks=5, num_channels=128):\n",
        "        super(ChessNet, self).__init__()\n",
        "        self.conv_input = nn.Conv2d(119, num_channels, kernel_size=3, padding=1, bias=False) \n",
        "        self.bn_input = nn.BatchNorm2d(num_channels)\n",
        "\n",
        "        self.res_blocks = nn.ModuleList([ResidualBlock(num_channels) for _ in range(num_residual_blocks)])\n",
        "\n",
        "        self.policy_conv = nn.Conv2d(num_channels, TOTAL_ACTION_PLANES, kernel_size=1, bias=False) \n",
        "        self.policy_bn = nn.BatchNorm2d(TOTAL_ACTION_PLANES) \n",
        "        self.value_conv = nn.Conv2d(num_channels, 1, kernel_size=1, bias=False)\n",
        "        self.value_bn = nn.BatchNorm2d(1)\n",
        "        self.value_fc1 = nn.Linear(1 * 8 * 8, 128) \n",
        "        self.value_fc2 = nn.Linear(128, 1) \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn_input(self.conv_input(x)))\n",
        "\n",
        "        for block in self.res_blocks:\n",
        "            x = block(x)\n",
        "\n",
        "        policy = F.relu(self.policy_bn(self.policy_conv(x)))\n",
        "        policy = policy.view(-1, POLICY_OUTPUT_SIZE) \n",
        "\n",
        "        value = F.relu(self.value_bn(self.value_conv(x)))\n",
        "        value = value.view(-1, 1 * 8 * 8) \n",
        "        value = F.relu(self.value_fc1(value))\n",
        "        value = torch.tanh(self.value_fc2(value)) \n",
        "\n",
        "        return policy, value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzIHQG8S3PlQ"
      },
      "source": [
        "# **Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_tbaq8FkSswv",
        "outputId": "a9af148a-19a5-4465-ccf2-58a50b6ff662"
      },
      "outputs": [],
      "source": [
        "def plot_imitation_metrics(policy_losses, value_losses, total_losses,\n",
        "                           policy_acc_top1, policy_acc_top5, value_maes,\n",
        "                           title_suffix=\"\"):\n",
        "    if not policy_losses:\n",
        "        print(\"No data to plot. Metric lists are empty.\")\n",
        "        return\n",
        "\n",
        "    num_plots = 3\n",
        "\n",
        "    fig, axs = plt.subplots(num_plots, 1, figsize=(10, num_plots * 4))\n",
        "\n",
        "    axs[0].plot(policy_losses, label=\"Policy Loss\")\n",
        "    axs[0].plot(value_losses, label=\"Value Loss\")\n",
        "    axs[0].plot(total_losses, label=\"Total Loss\", linestyle='--')\n",
        "    axs[0].set_title(f\"Losses per Epoch {title_suffix}\")\n",
        "    axs[0].set_xlabel(\"Epoch\")\n",
        "    axs[0].set_ylabel(\"Loss\")\n",
        "    axs[0].legend()\n",
        "    axs[0].grid(True)\n",
        "\n",
        "    axs[1].plot(policy_acc_top1, label=\"Policy Accuracy (Top-1)\")\n",
        "    axs[1].plot(policy_acc_top5, label=\"Policy Accuracy (Top-5)\")\n",
        "    axs[1].set_title(f\"Policy Accuracies per Epoch {title_suffix}\")\n",
        "    axs[1].set_xlabel(\"Epoch\")\n",
        "    axs[1].set_ylabel(\"Accuracy\")\n",
        "    axs[1].legend()\n",
        "    axs[1].grid(True)\n",
        "\n",
        "    axs[2].plot(value_maes, label=\"Value MAE\")\n",
        "    axs[2].set_title(f\"Value Mean Absolute Error per Epoch {title_suffix}\")\n",
        "    axs[2].set_xlabel(\"Epoch\")\n",
        "    axs[2].set_ylabel(\"MAE\")\n",
        "    axs[2].legend()\n",
        "    axs[2].grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    magnus_lichess_username = \"DrNykterstein\"\n",
        "    game_type_to_download = \"blitz\"\n",
        "    number_of_games_to_download = 1000\n",
        "    output_pgn_file = f\"magnus_carlsen_{game_type_to_download}_{number_of_games_to_download}_games_lc0_style.pgn\"\n",
        "\n",
        "    download_magnus_carlsen_game(\n",
        "        username=magnus_lichess_username,\n",
        "        max_games=number_of_games_to_download,\n",
        "        perf_type=game_type_to_download,\n",
        "        output_filename=output_pgn_file\n",
        "    )\n",
        "\n",
        "    X_data, Y_policy_data, Y_value_data = process_pgn_to_training_data_lc0(output_pgn_file, num_history_frames=7)\n",
        "\n",
        "    if X_data is not None and Y_policy_data is not None and Y_value_data is not None:\n",
        "        print(\"\\nLc0-style data preparation complete! Proceeding to training.\")\n",
        "\n",
        "        X_tensor_full = torch.from_numpy(X_data).float()\n",
        "        Y_policy_tensor_full = torch.from_numpy(Y_policy_data).long()\n",
        "        Y_value_tensor_full = torch.from_numpy(Y_value_data).float().unsqueeze(1)\n",
        "\n",
        "        full_dataset = TensorDataset(X_tensor_full, Y_policy_tensor_full, Y_value_tensor_full)\n",
        "\n",
        "        train_size = int(0.8 * len(full_dataset))\n",
        "        test_size = len(full_dataset) - train_size\n",
        "\n",
        "        train_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])\n",
        "\n",
        "        print(f\"Dataset split: Training samples: {len(train_dataset)}, Test samples: {len(test_dataset)}\")\n",
        "\n",
        "        batch_size = 256\n",
        "        train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "        test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        print(f\"Using device: {device}\")\n",
        "\n",
        "        model = ChessNet(num_residual_blocks=5, num_channels=128).to(device)\n",
        "        print(f\"Model created with {sum(p.numel() for p in model.parameters() if p.requires_grad)} trainable parameters.\")\n",
        "\n",
        "        criterion_policy = nn.CrossEntropyLoss()\n",
        "        criterion_value = nn.MSELoss()\n",
        "\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "        num_epochs = 20\n",
        "\n",
        "        train_policy_losses = []\n",
        "        train_value_losses = []\n",
        "        train_total_losses = []\n",
        "        train_policy_accuracies_top1 = []\n",
        "        train_policy_accuracies_top5 = []\n",
        "        train_value_maes = []\n",
        "\n",
        "        print(\"\\nStarting training...\")\n",
        "        for epoch in range(num_epochs):\n",
        "            model.train()\n",
        "            total_policy_loss_train = 0\n",
        "            total_value_loss_train = 0\n",
        "            total_loss_train = 0\n",
        "            total_correct_moves_top1_train = 0\n",
        "            total_correct_moves_top5_train = 0\n",
        "            total_samples_policy_train = 0\n",
        "            total_abs_value_diff_train = 0\n",
        "            total_value_samples_train = 0\n",
        "\n",
        "            for batch_idx, (batch_x, batch_y_policy, batch_y_value) in enumerate(train_dataloader):\n",
        "                batch_x, batch_y_policy, batch_y_value = batch_x.to(device), batch_y_policy.to(device), batch_y_value.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                policy_logits, predicted_value = model(batch_x)\n",
        "                loss_policy = criterion_policy(policy_logits, batch_y_policy)\n",
        "                loss_value = criterion_value(predicted_value, batch_y_value)\n",
        "                loss = loss_policy + loss_value\n",
        "\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                total_policy_loss_train += loss_policy.item()\n",
        "                total_value_loss_train += loss_value.item()\n",
        "                total_loss_train += loss.item()\n",
        "\n",
        "                _, predicted_moves = torch.max(policy_logits.data, 1)\n",
        "                total_correct_moves_top1_train += (predicted_moves == batch_y_policy).sum().item()\n",
        "                total_samples_policy_train += batch_y_policy.size(0)\n",
        "\n",
        "                top5_predicted_indices = torch.topk(policy_logits.data, k=5, dim=1).indices\n",
        "                for i in range(batch_y_policy.size(0)):\n",
        "                    if batch_y_policy[i] in top5_predicted_indices[i]:\n",
        "                        total_correct_moves_top5_train += 1\n",
        "\n",
        "                total_abs_value_diff_train += torch.abs(predicted_value - batch_y_value).sum().item()\n",
        "                total_value_samples_train += batch_y_value.size(0)\n",
        "\n",
        "            avg_policy_loss_train = total_policy_loss_train / len(train_dataloader)\n",
        "            avg_value_loss_train = total_value_loss_train / len(train_dataloader)\n",
        "            avg_total_loss_train = total_loss_train / len(train_dataloader)\n",
        "            avg_policy_accuracy_top1_train = total_correct_moves_top1_train / total_samples_policy_train if total_samples_policy_train > 0 else 0\n",
        "            avg_policy_accuracy_top5_train = total_correct_moves_top5_train / total_samples_policy_train if total_samples_policy_train > 0 else 0\n",
        "            avg_value_mae_train = total_abs_value_diff_train / total_value_samples_train if total_value_samples_train > 0 else 0\n",
        "\n",
        "            train_policy_losses.append(avg_policy_loss_train)\n",
        "            train_value_losses.append(avg_value_loss_train)\n",
        "            train_total_losses.append(avg_total_loss_train)\n",
        "            train_policy_accuracies_top1.append(avg_policy_accuracy_top1_train)\n",
        "            train_policy_accuracies_top5.append(avg_policy_accuracy_top5_train)\n",
        "            train_value_maes.append(avg_value_mae_train)\n",
        "            print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "            print(f\"  Train -> Policy Loss: {avg_policy_loss_train:.4f}, Policy Acc (Top-1): {avg_policy_accuracy_top1_train:.4f}, Policy Acc (Top-5): {avg_policy_accuracy_top5_train:.4f}, Value Loss: {avg_value_loss_train:.4f}, Value MAE: {avg_value_mae_train:.4f}, Total Loss: {avg_total_loss_train:.4f}\")\n",
        "\n",
        "        print(\"\\nTraining complete!\")\n",
        "\n",
        "        print(\"\\n--- Final Evaluation on Test Data ---\")\n",
        "        model.eval() \n",
        "        test_policy_loss = 0\n",
        "        test_value_loss = 0\n",
        "        test_total_loss = 0\n",
        "        test_correct_moves_top1 = 0\n",
        "        test_correct_moves_top5 = 0\n",
        "        test_samples_policy = 0\n",
        "        test_abs_value_diff = 0\n",
        "        test_value_samples = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_x, batch_y_policy, batch_y_value in test_dataloader: \n",
        "                batch_x, batch_y_policy, batch_y_value = batch_x.to(device), batch_y_policy.to(device), batch_y_value.to(device)\n",
        "\n",
        "                policy_logits, predicted_value = model(batch_x)\n",
        "\n",
        "                loss_policy = criterion_policy(policy_logits, batch_y_policy)\n",
        "                loss_value = criterion_value(predicted_value, batch_y_value)\n",
        "                loss = loss_policy + loss_value\n",
        "\n",
        "                test_policy_loss += loss_policy.item()\n",
        "                test_value_loss += loss_value.item()\n",
        "                test_total_loss += loss.item()\n",
        "\n",
        "                _, predicted_moves = torch.max(policy_logits.data, 1)\n",
        "                test_correct_moves_top1 += (predicted_moves == batch_y_policy).sum().item()\n",
        "                test_samples_policy += batch_y_policy.size(0)\n",
        "\n",
        "                top5_predicted_indices = torch.topk(policy_logits.data, k=5, dim=1).indices\n",
        "                for i in range(batch_y_policy.size(0)):\n",
        "                    if batch_y_policy[i] in top5_predicted_indices[i]:\n",
        "                        test_correct_moves_top5 += 1\n",
        "\n",
        "                test_abs_value_diff += torch.abs(predicted_value - batch_y_value).sum().item() \n",
        "                test_value_samples += batch_y_value.size(0)\n",
        "\n",
        "        avg_policy_loss_test = test_policy_loss / len(test_dataloader)\n",
        "        avg_value_loss_test = test_value_loss / len(test_dataloader)\n",
        "        avg_total_loss_test = test_total_loss / len(test_dataloader)\n",
        "        avg_policy_accuracy_top1_test = test_correct_moves_top1 / test_samples_policy if test_samples_policy > 0 else 0\n",
        "        avg_policy_accuracy_top5_test = test_correct_moves_top5 / test_samples_policy if test_samples_policy > 0 else 0\n",
        "        avg_value_mae_test = test_abs_value_diff / test_value_samples if test_value_samples > 0 else 0\n",
        "\n",
        "        print(f\"  Test  -> Policy Loss: {avg_policy_loss_test:.4f}, Policy Acc (Top-1): {avg_policy_accuracy_top1_test:.4f}, Policy Acc (Top-5): {avg_policy_accuracy_top5_test:.4f}, Value Loss: {avg_value_loss_test:.4f}, Value MAE: {avg_value_mae_test:.4f}, Total Loss: {avg_total_loss_test:.4f}\")\n",
        "\n",
        "        model_save_path = \"chess_model_lc0_imitation.pth\"\n",
        "        torch.save(model.state_dict(), model_save_path)\n",
        "        print(f\"Model saved to {model_save_path}\")\n",
        "        plot_imitation_metrics(\n",
        "            train_policy_losses,\n",
        "            train_value_losses,\n",
        "            train_total_losses,\n",
        "            train_policy_accuracies_top1,\n",
        "            train_policy_accuracies_top5,\n",
        "            train_value_maes,\n",
        "            title_suffix=\" (Imitation Learning Training)\"\n",
        "        )\n",
        "\n",
        "    else:\n",
        "        print(\"\\nFailed to prepare training data. Training skipped.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0UBxbbkBt5p2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDp0tVFltuJT"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3e1ad779ab9349fd8145f297af683682": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_d20c954761514ee5bfe4e4e0ed96448a",
            "msg_id": "",
            "outputs": [
              {
                "data": {
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\">   0%</span> <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #008000; text-decoration-color: #008000\">2,048/1,000,000 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">0:00:40</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">4:00:08</span> , <span style=\"color: #800000; text-decoration-color: #800000\">69 it/s</span> ]\n</pre>\n",
                  "text/plain": "\u001b[35m   0%\u001b[0m \u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2,048/1,000,000 \u001b[0m [ \u001b[33m0:00:40\u001b[0m < \u001b[36m4:00:08\u001b[0m , \u001b[31m69 it/s\u001b[0m ]\n"
                },
                "metadata": {},
                "output_type": "display_data"
              }
            ]
          }
        },
        "d20c954761514ee5bfe4e4e0ed96448a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
